# 検索（思い出す）

検索は「データベースだけで完結」させず、LLMが計画し、LLMが最終選別する。
品質最優先。

補足:

- 同期/非同期の繋がり（検索→SSE→更新）は `docs/10_実行フロー.md` を参照

## 全体構成（最小で2段）

1. LLM: 検索計画（短いJSON）
2. データベース: 候補収集（広く）
3. LLM: 選別 + 取得結果の整形（検索結果パック: `SearchResultPack`）

必要なら多段にしてよい（例: 追加質問の生成、再検索、時間推定の再実行）。

## 検索計画（`SearchPlan`）

目的:

- いまの入力に対して「どう探すか」を明示する
- 並列候補収集のパラメータを固定し、挙動を安定させる

出力は「JSONのみ」とする（前後に説明文を付けない）。

出力例（概略、キー名は識別子なので英語のまま）:

```json
{
  "mode": "associative_recent|targeted_broad|explicit_about_time",
  "queries": ["string"],
  "time_hint": {
    "about_year_start": null,
    "about_year_end": null,
    "life_stage_hint": "string"
  },
  "diversify": {
    "by": ["life_stage", "about_year_bucket"],
    "per_bucket": 5
  },
  "limits": {
    "max_candidates": 200,
    "max_selected": 12
  }
}
```

キーの意味（概略）:

- `mode`: 検索モード（最近の連想/全期間横断/時間指定）
- `queries`: ベクトル/文字n-gram向けの検索語
- `time_hint`: `about_time` と `life_stage` の手がかり
- `diversify`: 偏りを避けるための分散指定（例: `life_stage` ごとに均等に拾う）
- `limits`: 候補数/採用数の上限（主要経路を重くしないため）

## 検索モード（人間っぽさの分岐）

- 連想モード: 最近性（出来事ログの`created_at`/状態の`last_confirmed_at`）を強く効かせる
- 目的検索モード: 最近性を弱め、`life_stage`/年バケットで分散する
- 時間指定モード: `about_time` を強く使う（高校の頃/2018年 等）

## 候補収集（取りこぼし防止優先・並列）

候補は「取りこぼさない」を優先して広く集め、最後にLLMで絞る。
候補収集は、可能なものは **並列**で実行する（体感速度に効く）。
基本は「広め」を正とし、最後の選別（LLM）でノイズを落とす。

- 何でもかんでも検索対象にするとノイズになるため、「検索に効く保存」と「監査/説明用の保存」を分けて扱う

- ベクトル検索（意味）
- 文字n-gram検索（表記一致の補助）
  - 日本語は分かち書きに依存しない方式を使う（例: 文字3-gram）
- 文脈グラフの辿り（`event_threads` / `event_links`）
- 関係の辿り（エンティティ→関連→出来事）
- 時間フィルタ/分散（`life_stage`/年バケット）

## 何を「検索」できるようにするか

結論:

- **出来事ログ（`events`）/状態/要約（`summaries`）/文脈グラフ/感情**は検索に効く形で参照できるようにする
- **改訂履歴（`revisions`）**は基本は監査/説明用（デバッグ・「なぜ変えた？」）で、通常の会話検索の主要経路には入れない

検索パターン別に、効かせる情報は変わる:

- 「最近の連想」: 出来事ログ（`created_at`）+ 状態（`last_confirmed_at`）+ 文脈グラフの辿り
- 「全期間横断」: `about_time`（年/日レンジ） + `life_stage` の分散 + 要約（`summaries`）
- 「固有名詞/型番」: 文字n-gram
- 「あの時どう思ってた？」: `event_affect`（瞬間的な感情/内心）+ 長期の `long_mood_state`
- 「なんの文脈だっけ？」: 文脈グラフ（文脈スレッド/リンク）+ 文脈スレッド要約（`summaries`）

## 候補の統合（並列→統合→選別）

- 各候補収集処理は並列に候補を返す（候補には「ソース種別」を付ける）
- その後に重複排除し、ソースごとの上限（例: ベクトル 80 / 文字n-gram 80 / 文脈グラフ 80）を守って統合する
- 最終的な採用は LLM が行う（`SearchPlan` の意図に沿って選別）

## 文字検索（再検討メモ）

目的:

- 固有名詞/型番/短い語など、ベクトルだけだと取りこぼしやすいものを拾う

採用案（シンプル優先）:

- SQLite FTS5 の **`trigram`（文字3-gram）** を使う
  - 分かち書きが不要で安定する
  - 実装が軽い（追加依存が少ない）

代替案:

- 形態素解析（MeCab等）で分かち書きしてFTS（精度は上がる可能性があるが運用が重い）
- 文字列LIKE/正規表現（遅くなりやすい）

## 検索結果パック（`SearchResultPack`）

`SearchResultPack` は **検索結果（選別された記憶）** だけを指す。
「現在の文脈（`intent`/`now`/`client_context`）」は別扱いとし、検索結果と混ぜない。

要件:

- ユーザーへ露出しない
- 採用した根拠（なぜ採ったか）をログとして残せる形にする

推奨する中身（概念）:

- 採用項目の一覧（id、種別、短い抜粋）
- 重要なメタ（`created_at` / `last_confirmed_at` / `about_time` / `life_stage`）
- 採用理由（短文）
