# 検索（思い出す）

検索は「データベースだけで完結」させず、LLMが計画し、LLMが最終選別する。
品質最優先。

補足:

- 同期/非同期の繋がり（検索→SSE→更新）は `docs/10_実行フロー.md` を参照

## 全体構成（最小で2段）

1. LLM: 検索計画（短いJSON）
2. データベース: 候補収集（広く）
3. LLM: 選別 + 取得結果の整形（検索結果パック: `SearchResultPack`）

必要なら多段にしてよい（例: 追加質問の生成、再検索、時間推定の再実行）。

## 検索計画（`SearchPlan`）

目的:

- いまの入力に対して「どう探すか」を明示する
- 並列候補収集のパラメータを固定し、挙動を安定させる

出力は「JSONのみ」とする（前後に説明文を付けない）。

出力例（概略、キー名は識別子なので英語のまま）:

```json
{
  "mode": "associative_recent|targeted_broad|explicit_about_time",
  "queries": ["string"],
  "time_hint": {
    "about_year_start": null,
    "about_year_end": null,
    "life_stage_hint": "string"
  },
  "diversify": {
    "by": ["life_stage", "about_year_bucket"],
    "per_bucket": 5
  },
  "limits": {
    "max_candidates": 200,
    "max_selected": 12
  }
}
```

キーの意味（概略）:

- `mode`: 検索モード（最近の連想/全期間横断/時間指定）
- `queries`: ベクトル/文字n-gram向けの検索語
- `time_hint`: `about_time` と `life_stage` の手がかり
- `diversify`: 偏りを避けるための分散指定（例: `life_stage` ごとに均等に拾う）
- `limits`: 候補数/採用数の上限（主要経路を重くしないため）

## 検索モード（人間っぽさの分岐）

- 連想モード: 最近性（出来事ログの`created_at`/状態の`last_confirmed_at`）を強く効かせる
- 目的検索モード: 最近性を弱め、`life_stage`/年バケットで分散する
- 時間指定モード: `about_time` を強く使う（高校の頃/2018年 等）

## 候補収集（取りこぼし防止優先・並列）

候補は「取りこぼさない」を優先して広く集め、最後にLLMで絞る。
候補収集は、可能なものは **並列**で実行する（体感速度に効く）。
基本は「広め」を正とし、最後の選別（LLM）でノイズを落とす。

- 何でもかんでも検索対象にするとノイズになるため、「検索に効く保存」と「監査/説明用の保存」を分けて扱う
- 候補段階で「似た項目が多い」のは仕様（`events` / `state` / `event_affect` が同じ出来事に由来しやすい）

### 現状の候補収集（実装済み）

- ベクトル検索（意味）: `events` / `state` / `event_affects`
- 文字n-gram検索（表記一致の補助）: `events`（FTS5 trigram）
- 最近の出来事: `events.created_at` 降順
- 直前の流れ: `event_links(label="reply_to")` の連鎖
- 最近の状態: `state.last_confirmed_at` 降順
- `about_time` 補助: `SearchPlan.time_hint` がある場合のみ、`events.about_year_*` / `life_stage` で追加取得

### 追加予定の候補収集（未実装）

- 文脈スレッドの辿り（`event_threads`）
- エンティティ/関係の辿り（状態payloadや専用索引を使う）
- `life_stage`/年バケットの「分散」ロジックの本格適用（候補の偏りを抑える）

## 何を「検索」できるようにするか

結論:

- **出来事ログ（`events`）/状態（`state`）/要約（`state.kind="summary"`）/文脈グラフ/感情**は検索に効く形で参照できるようにする
- **改訂履歴（`revisions`）**は基本は監査/説明用（デバッグ・「なぜ変えた？」）で、通常の会話検索の主要経路には入れない

検索パターン別に、効かせる情報は変わる:

- 「最近の連想」: 出来事ログ（`created_at`）+ 状態（`last_confirmed_at`）+ 文脈グラフの辿り
- 「全期間横断」: `about_time`（年/日レンジ） + `life_stage` の分散 + 要約（`state.kind="summary"`）
- 「固有名詞/型番」: 文字n-gram
- 「あの時どう思ってた？」: `event_affect`（瞬間的な感情/内心）+ 長期の `long_mood_state`
- 「なんの文脈だっけ？」: 文脈グラフ（文脈スレッド/リンク）+ 文脈スレッド要約（`state.kind="summary"`、payloadでscopeを区別）

## 候補の統合（並列→統合→選別）

- 各候補収集処理は並列に候補を返す（候補には「ソース種別」を付ける）
- その後に重複排除し、ソースごとの上限（例: ベクトル 80 / 文字n-gram 80 / 文脈グラフ 80）を守って統合する
- 最終的な採用は LLM が行う（`SearchPlan` の意図に沿って選別）

注記:

- 同一IDの重複はバグなので必ず排除する
- 「近い意味の重複」は候補段階では許容し、`SearchResultPack` の選別で落とす（取りこぼし防止優先）
- 長期運用で `state` が増えすぎてノイズ化する場合は、非同期で整理（集約/過去化/要約育成）を行う（`docs/11_記憶整理（整える）.md`）

## 文字検索（再検討メモ）

目的:

- 固有名詞/型番/短い語など、ベクトルだけだと取りこぼしやすいものを拾う

採用案（シンプル優先）:

- SQLite FTS5 の **`trigram`（文字3-gram）** を使う
  - 分かち書きが不要で安定する
  - 実装が軽い（追加依存が少ない）

代替案:

- 形態素解析（MeCab等）で分かち書きしてFTS（精度は上がる可能性があるが運用が重い）
- 文字列LIKE/正規表現（遅くなりやすい）

## 検索結果パック（`SearchResultPack`）

`SearchResultPack` は **検索結果（選別された記憶）** だけを指す。
「現在の文脈（`intent`/`now`/`client_context`）」は別扱いとし、検索結果と混ぜない。

要件:

- ユーザーへ露出しない
- 採用した根拠（なぜ採ったか）をログとして残せる形にする

推奨する中身（概念）:

- 採用項目の一覧（id、種別、短い抜粋）
- 重要なメタ（`created_at` / `last_confirmed_at` / `about_time` / `life_stage`）
- 採用理由（短文）
