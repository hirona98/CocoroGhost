# 人格中心化（会話と自発行動）実装設計

<!-- Block: Purpose -->
## 目的

`persona_text / addon_text / second_person_label` を「口調」だけでなく、以下の全レイヤーで主変数として使う。

- 会話: 何を拾うか（検索/選別） + どう返すか（発話）
- 自発行動: 何を気にするか（Deliberation） + どう報告するか（Console表示/自発発話）
- 汎用委譲: backend 出力をそのまま見せず、人格の報告として再表現する

本設計は、`文字列比較での矯正` を行わず、構造化入力とプロンプト責務分離で人格中心化する。

<!-- Block: CurrentGap -->
## 現状の問題（要点）

### 1. 自発報告が人格発話になっていない

- `autonomy.message` は `ActionResult.summary_text` をそのまま使用している
- `summary_text` は Capability/backend 由来の内部要約であり、人格の発話ではない

結果:
- capability 的な口調
- backend 固有の書式（Markdownリンク等）
- ペルソナ非適用の文体

### 2. 会話の「何を拾うか」がペルソナ中心になっていない

- SearchResultPack 選別入力/選別プロンプトがペルソナ文脈を受け取らない
- RetrievalPlan は時間ヒント中心のルールベースで、人格の関心軸を使わない

結果:
- 返答本文の口調は人格でも、話題選択や注目点が人格に寄りにくい

### 3. 自発行動の材料選別も直近/優先度中心

- Deliberation 入力には `persona` を入れているが、入力の収集段階は非人格的

結果:
- 「人格として何を気にするか」の前に、材料が機械的に決まる

<!-- Block: DesignPrinciples -->
## 設計原則（固定）

- Capability/backend は「事実・結果」を返す（人格発話を作らない）
- 人格の発話は Ghost 内で生成する（`autonomy.message`）
- `autonomy.message` は `events.assistant_text` に保存してから publish する
- `publish した時点で発話成立` とする（ACK待ちしない）
- `autonomy.activity` は監視用であり、会話履歴の正本にはしない
- `文字列比較` で意味推定/矯正しない（本文解析を制御に使わない）
- `フォールバック処理を入れない`
  - 人格発話生成に失敗したら raw 要約を流さない
  - 失敗は `autonomy.activity` / ログで観測する

<!-- Block: AgreedDecisions -->
## 実装前の確定事項（本設計で採用）

- `autonomy.message` は **AI人格の発話** として扱う
  - `events.assistant_text` に保存してから publish する
  - `publish した時点で発話成立` とする（WebSocket ACKは待たない）
- `autonomy.activity` は **監視イベント** として扱う
  - 会話履歴の正本（`events.assistant_text`）には保存しない
  - 自発行動タブの監視表示を主用途にする
- `ActionDecision.console_delivery` は `do_action` 時に必須とする
  - 本文の意味解析ではなく、表示方針（`silent/activity_only/notify/chat` 等）の構造情報を持たせる
- `autonomy.message` の本文は Capability/backend の出力を素通ししない
  - `ActionResult.summary_text` / `result_payload` を入力事実として使い、人格層で再生成する
- `notify` 表示でも送信者は人格として扱う
  - 表示スタイルだけ通知寄りにする（送信者ラベルを `Autonomy` 固定にしない）

<!-- Block: Scope -->
## 対象範囲（Phase分割）

### Phase A（最優先: すぐ効く）

- `autonomy.message` 専用の人格発話生成を追加
- `web_access` / `agent_delegate` 出力を「内部結果」として扱う責務整理

### Phase B（次に必要: 判断/選別へ人格を入れる）

- 会話の SearchResultPack 選別に人格コンテキストを追加
- 自発行動 Deliberation の材料選別に人格軸を追加

### Phase C（長期本命: 興味の継続状態）

- `persona_interest_state`（仮）を導入
- 会話/自発で共通利用する「今この人格が気にしていること」を永続化

<!-- Block: PhaseAOverview -->
## Phase A 実装設計（人格発話の分離）

### ゴール

- `ActionResult.summary_text` をそのまま Console 発話に使わない
- `autonomy.message` は人格・気分・関係性を反映した発話として生成する
- `autonomy.activity` は監視用のまま維持する

### 変更方針

- `ActionResult.summary_text`: 内部要約（中立・機械向け）
- `autonomy.message`: 人格発話（会話整合用に `events.assistant_text` 保存）

### 新規処理フロー（`execute_intent` 完了 / `agent_job` callback 完了共通）

1. `ActionResult` / `action_result` event を保存（既存）
2. `autonomy.activity` を配信（既存拡張済み）
3. `console_delivery` が `chat/notify` の場合のみ人格発話生成を実行
4. 生成した人格発話を `Event(source="autonomy_message", assistant_text=...)` として保存
5. `autonomy.message` を publish（この時点で発話成立）
6. `autonomy_message` event に対して embedding / assistant_summary / WritePlan を投入（既存実装と同様）

### 失敗時ポリシー（重要）

- `autonomy.message` 生成に失敗した場合:
  - `autonomy.message` は出さない
  - `autonomy.activity` はそのまま残す
  - warning ログを出す
- `ActionResult.summary_text` の raw 素通しは行わない（フォールバック禁止）

<!-- Block: PhaseAMessageRender -->
## Phase A-1 `autonomy.message` 人格発話生成

### 追加する責務

`worker_handlers_autonomy.py` に「Console表示用の人格発話生成」を追加する。

- 想定ヘルパー名（例）:
  - `_render_autonomy_message_text(...)`

### 入力（構造化）

人格発話生成に渡す入力は、本文ではなく構造で渡す。

```json
{
  "persona": {
    "persona_text": "...",
    "addon_text": "...",
    "second_person_label": "マスター"
  },
  "mood": {
    "long_mood_state": {},
    "recent_vad_average": {"v": 0.0, "a": 0.0, "d": 0.0}
  },
  "decision": {
    "action_type": "web_research",
    "reason": "...",
    "persona_influence": {},
    "mood_influence": {},
    "console_delivery": {}
  },
  "result": {
    "result_status": "success",
    "capability_name": "web_access",
    "summary_text": "内部要約",
    "result_payload": {}
  },
  "agent_job": {
    "backend": "cli_agent",
    "job_id": "..."
  }
}
```

### 出力（最小）

- 文字列1本（`message`）
- `message_kind` は `console_delivery.message_kind` を尊重（生成結果に含めない）

### 初期実装の生成方針（Phase A-1）

- 入力事実の一次ソースは `ActionResult.result_payload`（あれば）を優先
- `ActionResult.summary_text` は内部要約として補助的に使う
- backend 生出力（例: `cli_agent` の stdout）は、そのまま読み上げず要約・再表現する
- 文字列テンプレート合成ではなく LLM 生成で人格化する（本文の文字列比較/矯正はしない）

### プロンプト方針

- `reply_system_prompt` をそのまま使うのではなく、`autonomy_message_render_system_prompt` を追加する
  - 理由:
    - 会話応答と自発報告では制約が違う
    - ただし人格規則（ペルソナ最優先、二人称固定、内部情報非表示）は同等に必要
- ただし、`reply_system_prompt` と人格規則の重複が増えすぎないよう、共通部を整理してもよい（将来）

### プロンプト要件（必須）

- あなたは AI人格本人として、自分の自発行動結果を報告する
- `ActionResult.summary_text` は内部要約であり、そのまま読まない
- `result_payload` の事実を優先し、backend固有の書式をそのまま真似しない
- Markdownリンクや機械的な列挙を避ける（必要なら自然文に要約）
- `console_delivery.message_kind` に応じたトーン
  - `report`: 落ち着いた報告
  - `progress`: 軽い進捗
  - `question`: 確認/問いかけ
  - `error`: 失敗報告（過度に機械的にしない）

### 実装対象ファイル（Phase A-1）

- `cocoro_ghost/prompt_builders.py`
  - `autonomy_message_render_system_prompt(...)`
  - `autonomy_message_render_user_prompt(...)`（または input JSON直渡し）
- `cocoro_ghost/worker_handlers_autonomy.py`
  - `_render_autonomy_message_text(...)` 追加
  - `_emit_autonomy_console_events_for_action_result(...)` を更新
- `cocoro_ghost/llm_client.py`
  - 必要なら purpose 追加（例: `ASYNC_AUTONOMY_MESSAGE_RENDER`）

<!-- Block: PhaseAInternalOutput -->
## Phase A-2 Capability/backend 出力の責務整理（内部結果化）

### `web_access`（`web_research`）

現状:
- capability prompt が `summary` を返す（これは内部結果でも表示文でもない曖昧な位置）

方針:
- `summary` は内部要約として扱う（中立）
- 人格発話は `autonomy.message` 生成でのみ作る

実装上の変更（最小）
- `web_access` の prompt 文書に「summary は内部要約」と明記
- `autonomy.message` 生成が導入されたら、`summary` の口調要求を弱める（事実優先）

### `agent_delegate(cli_agent)`

現状:
- backend stdout テキストが `summary_text` として保存される

方針:
- backend stdout は「内部結果」として扱う
- Console表示は必ず `autonomy.message` 側で人格再表現する

実装上の変更（推奨）
- `agent_runner`:
  - `details_json.raw_output_text` に stdout を残す
  - `summary_text` は短い内部要約（または backend出力の短縮版）
- `worker_handlers_autonomy.py`:
  - 人格発話生成入力で `details_json.raw_output_text` を参照可能にする

注記:
- backend（CLI agent）にペルソナ文脈を渡す設計は将来拡張として残す
- Phase A では Ghost 側の人格再表現だけで十分に改善できる

<!-- Block: PhaseBOverview -->
## Phase B 実装設計（何を気にするかを人格中心にする）

### Phase B-1 会話の SearchResultPack 選別に人格コンテキストを追加

#### 現状問題

- `selection_system_prompt()` はペルソナを参照しない
- `selection_input` も `persona/mood/preferences` を含まない

#### 追加する入力（`PersonaSelectionContext`）

`selection_input` に以下を追加する。

```json
{
  "persona_selection_context": {
    "second_person_label": "マスター",
    "persona_text": "...",
    "addon_text": "...",
    "long_mood_state": {},
    "recent_vad_average": {"v": 0.0, "a": 0.0, "d": 0.0},
    "confirmed_preferences": {},
    "interest_state": null
  }
}
```

#### 役割

- 選別LLMが「この人格なら何を思い出しやすいか」を判断できるようにする
- 最終返答の口調だけでなく、記憶選択の観点を人格寄りにする

#### 実装対象

- `cocoro_ghost/memory/_chat_mixin.py`
  - `selection_input` 構築部
- `cocoro_ghost/prompt_builders.py`
  - `selection_system_prompt()` の入力仕様/選別基準追記

### Phase B-2 RetrievalPlan に人格の関心軸を反映（ルールベース維持）

#### 現状問題

- `_build_rule_based_retrieval_plan()` が `user_input` + 時間ヒントのみ

#### 方針

- LLM SearchPlan は復活させない（速度優先）
- ルールベースのまま `PersonaFocusHint` を入力として受ける
- 文字列比較で persona 文を解析せず、構造化された関心状態/確定好みを使う

#### `PersonaFocusHint`（初期案）

```json
{
  "topic_bias": ["食べ物", "旅行", "ゲーム"],
  "style_bias": ["寄り添い", "具体"],
  "avoid_bias": ["刺激強め", "説教調"]
}
```

初期は `ConfirmedPreferences` と `interest_state`（未導入なら空）から構築する。

### Phase B-3 自発行動 Deliberation の材料選別を人格寄りにする

#### 現状問題

- `_collect_deliberation_input()` の events/states/goals/intents 収集が直近/優先度中心

#### 方針

- Deliberation入力そのものは維持しつつ、収集順/件数を `PersonaDeliberationFocus` で調整する
- 文字列比較ではなく、以下の構造情報を使う
  - `ConfirmedPreferences`
  - `LongMoodState`
  - `runtime_blackboard.attention_targets`
  - `goals`
  - `world_model_items`（将来的）

#### 実装方向

- `_collect_deliberation_input()` を肥大化させず、選別ヘルパへ分離（例: `autonomy/deliberation_input_builder.py`）
- 「収集」と「整形」の責務を分ける

<!-- Block: PhaseCOverview -->
## Phase C 実装設計（人格の関心・注目の継続状態）

### 目的

`LongMoodState`（気分）とは別に、「今この人格が何を気にしているか」を継続状態として持つ。

### 新規 state（案）

- `state.kind = "persona_interest_state"`（仮名）

### 内容（初期案）

```json
{
  "attention_targets": [
    {"type": "topic", "value": "天気", "weight": 0.7},
    {"type": "goal", "value": "goal_id:...", "weight": 0.9},
    {"type": "person", "value": "マスターの体調", "weight": 0.8}
  ],
  "interaction_mode": "observe|support|wait|explore",
  "updated_from_event_ids": [123, 124]
}
```

### 使い道

- 会話の SearchResultPack 選別
- RetrievalPlan の重み付け
- Deliberation入力の材料選別
- `autonomy.message` の報告優先度（何を報告したくなるか）

### 更新タイミング（候補）

- `apply_write_plan` 完了後
- `deliberate_once` 完了後（`persona_influence/mood_influence` を反映）
- `agent_delegate` 完了後（大型タスクの結果で関心が変わる場合）

<!-- Block: ConsoleContract -->
## Console 表示の実装契約（人格発話として扱う）

### `autonomy.message`

- `events.assistant_text` に保存済みの人格発話を配信する
- Console では「AI人格の発話」として扱う
- `notify` でも送信者ラベルを `Autonomy` 固定にせず、人格発話の見え方を維持する
  - 表示スタイルだけ通知寄りにする（送信者は人格）

### `autonomy.activity`

- 監視用イベントとして扱う（自発行動タブ）
- 会話履歴の正本にはしない
- `events.assistant_text` には保存しない（発話として扱わない）

<!-- Block: NoFallback -->
## 失敗時ポリシー（フォールバック禁止）

本設計では、人格中心化を優先するため以下を採用する。

- `autonomy.message` 生成失敗時:
  - raw summary 素通しをしない
  - `autonomy.message` を出さない
  - `autonomy.activity` + warning ログで観測する
- `selection` / `deliberation` / `message_render` の人格関連処理で不正JSON:
  - 既存方針どおり skip/drop
  - 文字列比較で修復しない

<!-- Block: FileMapping -->
## 実装マッピング（Phase別）

### Phase A

- `cocoro_ghost/prompt_builders.py`
  - `autonomy_message_render_*` prompt 追加
  - `autonomy_web_access_system_prompt()` の責務説明更新
- `cocoro_ghost/worker_handlers_autonomy.py`
  - `_render_autonomy_message_text(...)` 追加
  - `_emit_autonomy_console_events_for_action_result(...)` 更新
  - `autonomy.message` 再生成入力へ `confirmed_preferences` / `runtime_blackboard` を含める
- `cocoro_ghost/llm_client.py`
  - `LlmRequestPurpose.ASYNC_AUTONOMY_MESSAGE_RENDER`（必要なら）
- `cocoro_ghost/agent_runner.py`
  - `details_json.raw_output_text` の扱い整理（推奨）
- `CocoroConsole/Services/CommunicationService.cs`
  - `autonomy.message` の `notify` 表示を人格発話扱いへ調整
- `cocoro_ghost/worker_handlers_write_plan_generate.py`
  - WritePlan 生成で無人格フォールバックを使わず、人格設定取得失敗は失敗扱いにする
- `cocoro_ghost/prompt_builders.py`
  - `write_plan_system_prompt()` で `addon_text` も参照し、記憶更新の関心軸へ反映する

### Phase B

- `cocoro_ghost/memory/_chat_mixin.py`
  - `selection_input` へ `persona_selection_context` を追加
  - RetrievalPlan への `PersonaFocusHint` 反映
- `cocoro_ghost/prompt_builders.py`
  - `selection_system_prompt()` を人格対応に拡張
- `cocoro_ghost/worker_handlers_autonomy.py`（または新規builder）
  - Deliberation材料選別の人格化
  - 実装済み（第一段階）:
    - `confirmed_preferences` / `runtime_blackboard` / `persona_deliberation_focus` を Deliberation入力へ追加
    - `intent/goal/state/event` の並び順と件数を構造情報ベースで調整
    - 文字列比較による意味推定は使わない
  - 未実装（次段階）:
    - `persona_interest_state` に基づく attention_targets の本格運用
    - world_model_items を使った関心ベースの材料選別

### Phase C

- `cocoro_ghost/worker_handlers_write_plan_apply.py`（または専用worker）
  - `persona_interest_state` 更新
- `cocoro_ghost/memory_models.py`
  - 既存 `states` の `kind` 拡張で足りるなら新テーブル不要
- `cocoro_ghost/prompt_builders.py`
  - 会話/自発向け prompt で `interest_state` を参照

<!-- Block: Acceptance -->
## 受け入れ条件（人格中心化）

### Phase A

- `autonomy.message` の文面が Capability/backend の口調・Markdown書式を直接含まない
- `autonomy.message` が `events.assistant_text` に保存され、後続会話で参照される
- `do_action` の ActionDecision に `console_delivery` が必ず含まれる
- `autonomy.activity` が会話履歴（`events.assistant_text`）へ混入しない
- `autonomy.message` 生成失敗時に raw summary 素通しが起きない

### Phase B

- SearchResultPack 選別が `persona_selection_context` を受ける
- 同一入力でもペルソナ差で選ばれやすい記憶の傾向が変わる（観測可能）
- Deliberation の材料選別で `persona/mood/attention` が使われる
  - 第一段階: `confirmed_preferences/mood/runtime_blackboard` に基づく並び順・件数調整
  - 次段階: `persona_interest_state` / world_model_items を使った注目対象選別

### Phase C

- `persona_interest_state` が継続更新される
- 会話/自発の両方で同じ関心状態を参照できる
